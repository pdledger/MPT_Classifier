{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d641378",
   "metadata": {},
   "source": [
    "**The first thing to do is to run Creator.py to setup the dataset. First specify the options**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2be154fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# The Name of the Dataset\n",
    "Name = \"Magnetic-Knives/Knives-100-inv\"\n",
    "\n",
    "# Frequency Array\n",
    "Frequencies=np.array([119.25,178.875,238.5,298.125,357.75,477,596.25,715.5,954,1192.5,1431,1908,2385,2862,3816,4770,5724,7632,9540,12402,16218,20988,26712,34344,43884,57240,73458,95400])\n",
    "Frequencies = Frequencies*6.28 #Convert to rad/s'\n",
    "#Frequencies=np.logspace(2,8,50)\n",
    "#Frequencies = np.genfromtxt(\"Classes_Paul/Class_Knives/OBJ_Knife_Cheap_Chef_Magnetic/al_0.001_mu_67.5_sig_1.45e6/1e1-1e10_243_el_15479_ord_4_POD_13_1e-6/Data/Frequencies.csv\",delimiter = ',')\n",
    "\n",
    "# Classes to Include\n",
    "Classes = [\"Knives\"]\n",
    "#\n",
    "# Global number of results\n",
    "# Coin Problem\n",
    "extend_results = 'global_obj'\n",
    "\n",
    "# Number of secondary results if 'global_obj'\n",
    "\n",
    "# Knife problem\n",
    "Num_Results = 100\n",
    "\n",
    "# Classes if 'global_class' or 'classwise'\n",
    "class_split=[]\n",
    "\n",
    "# Name each of the classes this is done in order\n",
    "class_names = []\n",
    "\n",
    "# Number of results if 'global_class'\n",
    "Num_Results_class = []\n",
    "\n",
    "\n",
    "# (int) Number of results per class results per class if 'classwise'\n",
    "class_num_results = []\n",
    "\n",
    "#Labeler False,'Classwise', 'Objectwise'\n",
    "Label_Data = 'Objectwise'\n",
    "Name_Objects = True\n",
    "\n",
    "#(dictionary) name the objects as you wish them to appear in the classificaiton\n",
    "\n",
    "#OBJ_Knife_Cheap_Chef             OBJ_Knife_Cleaver           OBJ_Knife_Wusthof\n",
    "#OBJ_Knife_Cheap_Chef_Magnetic    OBJ_Knife_Cleaver_Magnetic  OBJ_Knife_Wusthof_Magnetic\n",
    "#OBJ_Knife_Cheap_Cutlet           OBJ_Knife_Santoku\n",
    "#OBJ_Knife_Cheap_Cutlet_Magnetic  OBJ_Knife_Santoku_Magnetic\n",
    "\n",
    "Object_Names_dictionary ={\"Knife_Cheap_Chef\": r\"Chef\", \"Knife_Cheap_Chef_Magnetic\": r\"Chef Mag.\",\\\n",
    "                          \"Knife_Cheap_Cutlet\": r\"Cutlet\", \"Knife_Cheap_Cutlet_Magnetic\": r\"Cutlet Mag.\",\\\n",
    "                          \"Knife_Cleaver\": r\"Cleaver\", \"Knife_Cleaver_Magnetic\": r\"Cleaver Mag\",\\\n",
    "                          \"Knife_Santoku\": r\"Santoku\", \"Knife_Santoku_Magnetic\": r\"Santoku Mag.\",\\\n",
    "                          \"Knife_Wusthof\":r\"Wusthof\", \"Knife_Wusthof_Magnetic\":r\"Wusthof Mag.\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Name_Order = [\"Knife_Cheap_Chef\", \"Knife_Cheap_Chef_Magnetic\",\\\n",
    "                          \"Knife_Cheap_Cutlet\", \"Knife_Cheap_Cutlet_Magnetic\",\\\n",
    "                          \"Knife_Cleaver\", \"Knife_Cleaver_Magnetic\",\\\n",
    "                          \"Knife_Santoku\", \"Knife_Santoku_Magnetic\",\\\n",
    "                          \"Knife_Wusthof\", \"Knife_Wusthof_Magnetic\"]\n",
    "\n",
    "#How to scale\n",
    "Scale_type = 'Global'\n",
    "\n",
    "#Which file (This is not currently used)\n",
    "Scale_File = 'Coin_DataSet.csv'\n",
    "\n",
    "\n",
    "#Alpha scale\n",
    "Alpha_scale = 0.84\n",
    "\n",
    "#Sigma scale\n",
    "Sigma_scale = 12.5\n",
    "\n",
    "# Path Name for where the class data is stored\n",
    "Class_dir = \"Classes_Paul\"\n",
    "\n",
    "# Create a dictionary of these settings\n",
    "Creator_Settings = {\"Name\":Name,\"Frequencies\":Frequencies,\"Classes\":Classes,\"extend_results\":extend_results,\"Num_Results\":Num_Results,#\n",
    "                    \"class_split\":class_split,\"class_names\":class_names,\"Num_Results_class\":Num_Results_class,\"class_num_results\":class_num_results,\\\n",
    "                    \"Label_Data\":Label_Data,\"Name_Objects\":Name_Objects,\"Object_Names_dictionary\":Object_Names_dictionary,\"Name_Order\":Name_Order,\\\n",
    "                    \"Scale_type\":Scale_type,\"Scale_File\":Scale_File,\"Alpha_scale\":Alpha_scale,\"Sigma_scale\":Sigma_scale, \"Class_dir\":Class_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf2c8608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder path to the dataset is: Magnetic-Knives/Knives-100-inv_Al_0.84_Sig_12.5\n",
      "Class type is a list\n",
      "Knife_Wusthof\n",
      "Knife_Santoku\n",
      "Knife_Cleaver_Magnetic\n",
      "Knife_Wusthof_Magnetic\n",
      "Knife_Santoku_Magnetic\n",
      "Knife_Cleaver\n",
      "Knife_Cheap_Cutlet_Magnetic\n",
      "Knife_Cheap_Chef\n",
      "Knife_Cheap_Chef_Magnetic\n",
      "Knife_Cheap_Cutlet\n",
      "(1100, 28) 28\n"
     ]
    }
   ],
   "source": [
    "# Run the Creator script\n",
    "from Creator import *\n",
    "#DataSet_Name=Creator(Name,Frequencies,Classes,extend_results,Num_Results,class_split,class_names,\\\n",
    "#            Num_Results_class,class_num_results,Label_Data, Name_Objects,Object_Names_dictionary,Name_Order,Scale_type,Scale_File,\\\n",
    "#            Alpha_scale,Sigma_scale)\n",
    "DataSet_Name=Creator(Creator_Settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96be8df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnetic-Knives/Knives-100-inv_Al_0.84_Sig_12.5\n"
     ]
    }
   ],
   "source": [
    "# This is the dataset name to be used with the classifier\n",
    "#DataSet_Name=\"Magnetic-Knives/Knives-500-inv_Al_0.84_Sig_12.5\"\n",
    "DataSet_Name=\"Magnetic-Knives/Knives-100-inv_Al_0.84_Sig_12.5\"\n",
    "print(DataSet_Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb993227",
   "metadata": {},
   "source": [
    "**The next part involves running the actual classifier. This is done using Trainer_PDL.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adca0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option to load external testing data from disk. Requires that external_file_loader.py be run first.\n",
    "Load_External_Data = False \n",
    "# Option to plot comparison figures between the input array of simulated data and the external test data.\n",
    "# Currently only supported for a single class test set.\n",
    "Plot_Comparison_Figures = True\n",
    "# Option to additionally save to disk: the model for each bootstrap iteration, the normalisation coefficients for each,\n",
    "# bootstrap iteration, and the input array for each model, Used for debugging.\n",
    "Full_Save = False\n",
    "\n",
    "# Option to use SVD to reduce the number of features\n",
    "Reduce_Features = False\n",
    "\n",
    "#Model to be used\n",
    "#Optional models 'LogisticRegression', 'SVM', 'DecisionTree', 'RandomForest', 'GradientBoost', 'MLP','MLP,(n1,n2,...,nn)'\n",
    "Models_to_run = ['LogisticRegression']#,'SVM','GradientBoost']\n",
    "\n",
    "#Features\n",
    "Features = ['AngleRtildeI']#'Pri1','Pri2','Pri3','AngleRtildeI']#\n",
    "# Features = ['Eig1', 'Eig2', 'Eig3']\n",
    "#(list) list of features to be used options:\n",
    "#'Eig1','Eig2','Eig3','Pri1','Pri2','Pri3','Dev2','Dev3','Com','AngleRtildeI'\n",
    "#Eigenvalues, Principal invarients, Deviatoric invarients, Comutator, Angle between Rtilde and I\n",
    "\n",
    "#How many times would you like to train the model\n",
    "Bootstrap_Repetitions = 1\n",
    "#(int) how many times to train the model to obtain an average accuracy\n",
    "\n",
    "# use default levels of SNR\n",
    "SNR_array=[]\n",
    "\n",
    "# Make plot of first two reduced invairants\n",
    "Plot_Principal_Componenets = False\n",
    "\n",
    "Trainer_Settings = {\"DataSet_Name\": DataSet_Name, \"Load_External_Data\":Load_External_Data, \"Plot_Comparison_Figures\":Plot_Comparison_Figures,\\\n",
    "                   \"Full_Save\": Full_Save, \"Reduce_Features\":Reduce_Features, \"Models_to_run\": Models_to_run, \"Features\":Features, #\n",
    "                    \"Bootstrap_Repetitions\": Bootstrap_Repetitions, \"SNR_array\": SNR_array, \"Plot_Principal_Componenets\": Plot_Principal_Componenets }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d510a2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 22:09:55.370156: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-17 22:09:55.372023: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-17 22:09:55.406845: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-17 22:09:55.407637: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-17 22:09:56.141618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level =  5\n",
      "(1100, 504)\n",
      "(1100, 30) (1100, 28)\n",
      "Data [[ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.88752697e-03\n",
      "   3.06630952e-03  2.29702013e-03]\n",
      " [ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.36776142e-03\n",
      "   2.60568053e-03  1.94502296e-03]\n",
      " [ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.73385821e-03\n",
      "   2.93332778e-03  2.18037322e-03]\n",
      " ...\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  6.38252029e-06\n",
      "   8.77365434e-06  1.29175978e-05]\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  5.96078656e-06\n",
      "   8.09323125e-06  1.17695614e-05]\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  7.56427421e-06\n",
      "   1.06919878e-05  1.62085050e-05]]\n",
      "to here\n",
      "LogisticRegression\n",
      "Noise level =  10\n",
      "(1100, 504)\n",
      "(1100, 30) (1100, 28)\n",
      "Data [[ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.88752697e-03\n",
      "   3.06630952e-03  2.29702013e-03]\n",
      " [ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.36776142e-03\n",
      "   2.60568053e-03  1.94502296e-03]\n",
      " [ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.73385821e-03\n",
      "   2.93332778e-03  2.18037322e-03]\n",
      " ...\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  6.38252029e-06\n",
      "   8.77365434e-06  1.29175978e-05]\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  5.96078656e-06\n",
      "   8.09323125e-06  1.17695614e-05]\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  7.56427421e-06\n",
      "   1.06919878e-05  1.62085050e-05]]\n",
      "to here\n",
      "LogisticRegression\n",
      "Noise level =  15\n",
      "(1100, 504)\n",
      "(1100, 30) (1100, 28)\n",
      "Data [[ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.88752697e-03\n",
      "   3.06630952e-03  2.29702013e-03]\n",
      " [ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.36776142e-03\n",
      "   2.60568053e-03  1.94502296e-03]\n",
      " [ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.73385821e-03\n",
      "   2.93332778e-03  2.18037322e-03]\n",
      " ...\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  6.38252029e-06\n",
      "   8.77365434e-06  1.29175978e-05]\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  5.96078656e-06\n",
      "   8.09323125e-06  1.17695614e-05]\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  7.56427421e-06\n",
      "   1.06919878e-05  1.62085050e-05]]\n",
      "to here\n",
      "LogisticRegression\n",
      "Noise level =  20\n",
      "(1100, 504)\n",
      "(1100, 30) (1100, 28)\n",
      "Data [[ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.88752697e-03\n",
      "   3.06630952e-03  2.29702013e-03]\n",
      " [ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.36776142e-03\n",
      "   2.60568053e-03  1.94502296e-03]\n",
      " [ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.73385821e-03\n",
      "   2.93332778e-03  2.18037322e-03]\n",
      " ...\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  6.38252029e-06\n",
      "   8.77365434e-06  1.29175978e-05]\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  5.96078656e-06\n",
      "   8.09323125e-06  1.17695614e-05]\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  7.56427421e-06\n",
      "   1.06919878e-05  1.62085050e-05]]\n",
      "to here\n",
      "LogisticRegression\n",
      "Noise level =  40\n",
      "(1100, 504)\n",
      "(1100, 30) (1100, 28)\n",
      "Data [[ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.88752697e-03\n",
      "   3.06630952e-03  2.29702013e-03]\n",
      " [ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.36776142e-03\n",
      "   2.60568053e-03  1.94502296e-03]\n",
      " [ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.73385821e-03\n",
      "   2.93332778e-03  2.18037322e-03]\n",
      " ...\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  6.38252029e-06\n",
      "   8.77365434e-06  1.29175978e-05]\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  5.96078656e-06\n",
      "   8.09323125e-06  1.17695614e-05]\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  7.56427421e-06\n",
      "   1.06919878e-05  1.62085050e-05]]\n",
      "to here\n",
      "LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "from Trainer_PDL import *\n",
    "\n",
    "#main(DataSet_Name,Load_External_Data,Plot_Comparison_Figures,Full_Save,Reduce_Features,Models_to_run,Features,Bootstrap_Repetitions)\n",
    "main(Trainer_Settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b5a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f4d7e-007a-470d-a072-3910c7c28cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
