{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d641378",
   "metadata": {},
   "source": [
    "**The first thing to do is to run Creator.py to setup the dataset. First specify the options**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2be154fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# The Name of the Dataset\n",
    "Name = \"Magnetic-Knives/Knives-500-inv\"\n",
    "\n",
    "# Frequency Array\n",
    "Frequencies=np.array([119.25,178.875,238.5,298.125,357.75,477,596.25,715.5,954,1192.5,1431,1908,2385,2862,3816,4770,5724,7632,9540,12402,16218,20988,26712,34344,43884,57240,73458,95400])\n",
    "Frequencies = Frequencies*6.28 #Convert to rad/s'\n",
    "\n",
    "# Classes to Include\n",
    "Classes = [\"Knives\"]\n",
    "#\n",
    "# Global number of results\n",
    "# Coin Problem\n",
    "extend_results = 'global_obj'\n",
    "\n",
    "# Number of secondary results if 'global_obj'\n",
    "\n",
    "# Knife problem\n",
    "Num_Results = 500\n",
    "\n",
    "# Classes if 'global_class' or 'classwise'\n",
    "class_split=[]\n",
    "\n",
    "# Name each of the classes this is done in order\n",
    "class_names = []\n",
    "\n",
    "# Number of results if 'global_class'\n",
    "Num_Results_class = []\n",
    "\n",
    "\n",
    "# (int) Number of results per class results per class if 'classwise'\n",
    "class_num_results = []\n",
    "\n",
    "#Labeler False,'Classwise', 'Objectwise'\n",
    "Label_Data = 'Objectwise'\n",
    "Name_Objects = True\n",
    "\n",
    "#(dictionary) name the objects as you wish them to appear in the classificaiton\n",
    "\n",
    "#OBJ_Knife_Cheap_Chef             OBJ_Knife_Cleaver           OBJ_Knife_Wusthof\n",
    "#OBJ_Knife_Cheap_Chef_Magnetic    OBJ_Knife_Cleaver_Magnetic  OBJ_Knife_Wusthof_Magnetic\n",
    "#OBJ_Knife_Cheap_Cutlet           OBJ_Knife_Santoku\n",
    "#OBJ_Knife_Cheap_Cutlet_Magnetic  OBJ_Knife_Santoku_Magnetic\n",
    "\n",
    "Object_Names_dictionary ={\"Knife_Cheap_Chef\": r\"Chef\", \"Knife_Cheap_Chef_Magnetic\": r\"Chef Mag.\",\\\n",
    "                          \"Knife_Cheap_Cutlet\": r\"Cutlet\", \"Knife_Cheap_Cutlet_Magnetic\": r\"Cutlet Mag.\",\\\n",
    "                          \"Knife_Cleaver\": r\"Cleaver\", \"Knife_Cleaver_Magnetic\": r\"Cleaver Mag\",\\\n",
    "                          \"Knife_Santoku\": r\"Santoku\", \"Knife_Santoku_Magnetic\": r\"Santoku Mag.\",\\\n",
    "                          \"Knife_Wusthof\":r\"Wusthof\", \"Knife_Wusthof_Magnetic\":r\"Wusthof Mag.\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Name_Order = [\"Knife_Cheap_Chef\", \"Knife_Cheap_Chef_Magnetic\",\\\n",
    "                          \"Knife_Cheap_Cutlet\", \"Knife_Cheap_Cutlet_Magnetic\",\\\n",
    "                          \"Knife_Cleaver\", \"Knife_Cleaver_Magnetic\",\\\n",
    "                          \"Knife_Santoku\", \"Knife_Santoku_Magnetic\",\\\n",
    "                          \"Knife_Wusthof\", \"Knife_Wusthof_Magnetic\"]\n",
    "\n",
    "#How to scale\n",
    "Scale_type = 'Global'\n",
    "\n",
    "#Which file (This is not currently used)\n",
    "Scale_File = 'Coin_DataSet.csv'\n",
    "\n",
    "\n",
    "#Alpha scale\n",
    "Alpha_scale = 0.84\n",
    "\n",
    "#Sigma scale\n",
    "Sigma_scale = 12.5\n",
    "\n",
    "# Path Name for where the class data is stored\n",
    "Class_dir = \"Classes_Paul\"\n",
    "\n",
    "# Create a dictionary of these settings\n",
    "Creator_Settings = {\"Name\":Name,\"Frequencies\":Frequencies,\"Classes\":Classes,\"extend_results\":extend_results,\"Num_Results\":Num_Results,#\n",
    "                    \"class_split\":class_split,\"class_names\":class_names,\"Num_Results_class\":Num_Results_class,\"class_num_results\":class_num_results,\\\n",
    "                    \"Label_Data\":Label_Data,\"Name_Objects\":Name_Objects,\"Object_Names_dictionary\":Object_Names_dictionary,\"Name_Order\":Name_Order,\\\n",
    "                    \"Scale_type\":Scale_type,\"Scale_File\":Scale_File,\"Alpha_scale\":Alpha_scale,\"Sigma_scale\":Sigma_scale, \"Class_dir\":Class_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf2c8608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder path to the dataset is: Magnetic-Knives/Knives-500-inv_Al_0.84_Sig_12.5\n",
      "Class type is a list\n",
      "Knife_Wusthof\n",
      "Knife_Santoku\n",
      "Knife_Cleaver_Magnetic\n",
      "Knife_Wusthof_Magnetic\n",
      "Knife_Santoku_Magnetic\n",
      "Knife_Cleaver\n",
      "Knife_Cheap_Cutlet_Magnetic\n",
      "Knife_Cheap_Chef\n",
      "Knife_Cheap_Chef_Magnetic\n",
      "Knife_Cheap_Cutlet\n",
      "(5500, 28) 28\n"
     ]
    }
   ],
   "source": [
    "# Run the Creator script\n",
    "from Creator import *\n",
    "#DataSet_Name=Creator(Name,Frequencies,Classes,extend_results,Num_Results,class_split,class_names,\\\n",
    "#            Num_Results_class,class_num_results,Label_Data, Name_Objects,Object_Names_dictionary,Name_Order,Scale_type,Scale_File,\\\n",
    "#            Alpha_scale,Sigma_scale)\n",
    "DataSet_Name=Creator(Creator_Settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96be8df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnetic-Knives/Knives-500-inv_Al_0.84_Sig_12.5\n"
     ]
    }
   ],
   "source": [
    "# This is the dataset name to be used with the classifier\n",
    "\n",
    "print(DataSet_Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb993227",
   "metadata": {},
   "source": [
    "**The next part involves running the actual classifier. This is done using Trainer_PDL.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adca0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option to load external testing data from disk. Requires that external_file_loader.py be run first.\n",
    "Load_External_Data = False \n",
    "# Option to plot comparison figures between the input array of simulated data and the external test data.\n",
    "# Currently only supported for a single class test set.\n",
    "Plot_Comparison_Figures = False\n",
    "# Option to additionally save to disk: the model for each bootstrap iteration, the normalisation coefficients for each,\n",
    "# bootstrap iteration, and the input array for each model, Used for debugging.\n",
    "Full_Save = False\n",
    "\n",
    "# Option to use SVD to reduce the number of features\n",
    "Reduce_Features = True\n",
    "\n",
    "#Model to be used\n",
    "#Optional models 'LogisticRegression', 'SVM', 'DecisionTree', 'RandomForest', 'GradientBoost', 'MLP','MLP,(n1,n2,...,nn)'\n",
    "Models_to_run = ['LogisticRegression']#,'SVM','GradientBoost']\n",
    "\n",
    "#Features\n",
    "Features = ['Pri1','Pri2','Pri3']#,'AngleRtildeI']#\n",
    "# Features = ['Eig1', 'Eig2', 'Eig3']\n",
    "#(list) list of features to be used options:\n",
    "#'Eig1','Eig2','Eig3','Pri1','Pri2','Pri3','Dev2','Dev3','Com','AngleRtildeI'\n",
    "#Eigenvalues, Principal invarients, Deviatoric invarients, Comutator, Angle between Rtilde and I\n",
    "\n",
    "#How many times would you like to train the model\n",
    "Bootstrap_Repetitions = 1\n",
    "#(int) how many times to train the model to obtain an average accuracy\n",
    "\n",
    "# use default levels of SNR\n",
    "SNR_array=[]\n",
    "\n",
    "# Make plot of first two reduced invairants\n",
    "Plot_Principal_Componenets = True\n",
    "\n",
    "Trainer_Settings = {\"DataSet_Name\": DataSet_Name, \"Load_External_Data\":Load_External_Data, \"Plot_Comparison_Figures\":Plot_Comparison_Figures,\\\n",
    "                   \"Full_Save\": Full_Save, \"Reduce_Features\":Reduce_Features, \"Models_to_run\": Models_to_run, \"Features\":Features, #\n",
    "                    \"Bootstrap_Repetitions\": Bootstrap_Repetitions, \"SNR_array\": SNR_array, \"Plot_Principal_Componenets\": Plot_Principal_Componenets }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d510a2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level =  5\n",
      "(5500, 504)\n",
      "(5500, 170) (5500, 168)\n",
      "Data [[ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.88752697e-03\n",
      "   3.06630952e-03  2.29702013e-03]\n",
      " [ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  4.26654638e-03\n",
      "   3.38283627e-03  2.58451588e-03]\n",
      " [ 3.23149683e-05  3.21463968e-05  3.19125971e-05 ...  3.41801885e-03\n",
      "   2.65143067e-03  1.96990547e-03]\n",
      " ...\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  1.25105280e-05\n",
      "   1.90041707e-05  3.18867247e-05]\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  9.78220686e-06\n",
      "   1.43535047e-05  2.27739029e-05]\n",
      " [-2.90171871e-10 -6.52877846e-10 -1.16064569e-09 ...  9.15635306e-06\n",
      "   1.33107232e-05  2.08597014e-05]]\n",
      "to here\n",
      "LogisticRegression\n",
      "4125 168\n",
      " SVD complete      \n",
      "Reduced the number of features from 168  to  118\n",
      "(4125, 118)\n",
      "(4125,)\n",
      "Completed predictions\n",
      "Completed plotting\n",
      "Found 1375  Results\n",
      "(1375, 10) (1375, 10) (1375, 10)\n"
     ]
    }
   ],
   "source": [
    "from Trainer_PDL import *\n",
    "\n",
    "#main(DataSet_Name,Load_External_Data,Plot_Comparison_Figures,Full_Save,Reduce_Features,Models_to_run,Features,Bootstrap_Repetitions)\n",
    "main(Trainer_Settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b5a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f4d7e-007a-470d-a072-3910c7c28cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
