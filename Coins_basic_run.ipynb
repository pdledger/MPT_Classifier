{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d641378",
   "metadata": {},
   "source": [
    "**The first thing to do is to run Creator.py to setup the dataset. First specify the options**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2be154fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# The Name of the Dataset\n",
    "Name = \"British-Coins-Updated-1p-2p/Coins-100-inv\"\n",
    "\n",
    "# Frequency Array\n",
    "Frequencies=np.array([119.25,178.875,238.5,298.125,357.75,477,596.25,715.5,954,1192.5,1431,1908,2385,2862,3816,4770,5724,7632,9540,12402,16218,20988,26712,34344,43884,57240,73458,95400])\n",
    "Frequencies = Frequencies*6.28 #Convert to rad/s'\n",
    "#Frequencies=np.logspace(2,8,150)\n",
    "\n",
    "# Classes to Include\n",
    "Classes = [\"British_Coins_Updated_1p_2p\"]\n",
    "#\n",
    "# Global number of results\n",
    "# Coin Problem\n",
    "extend_results = 'global_obj'\n",
    "\n",
    "# Number of secondary results if 'global_obj'\n",
    "\n",
    "#Coin Problem`\n",
    "Num_Results = 100\n",
    "\n",
    "# Classes if 'global_class' or 'classwise'\n",
    "class_split=[]\n",
    "\n",
    "# Name each of the classes this is done in order\n",
    "class_names = []\n",
    "\n",
    "# Number of results if 'global_class'\n",
    "Num_Results_class = []\n",
    "\n",
    "\n",
    "# (int) Number of results per class results per class if 'classwise'\n",
    "class_num_results = []\n",
    "\n",
    "#Labeler False,'Classwise', 'Objectwise'\n",
    "Label_Data = 'Objectwise'\n",
    "Name_Objects = True\n",
    "\n",
    "#(dictionary) name the objects as you wish them to appear in the classificaiton\n",
    "Object_Names_dictionary ={\"Two_Pound\":r\"£2\", \"Ten_Pence\":r\"10p_(new)\", \"Ten_Pence_non_magnetic\":r\"10p_(old)\", \"One_Pound\":r\"£1\", \"Two_Penny\":r\"2p_(new)\",\n",
    "                              \"Two_Penny_non_magnetic\":r\"2p_(old)\", \"Twenty_Pence\":r\"20p\", \"Five_Pence\":r\"5p_(new)\", \"Five_Pence_non_magnetic\":r\"5p_(old)\",\n",
    "                              \"Fifty_Pence\":r\"50p\", \"One_Penny\":r\"1p_(new)\", \"One_Penny_non_magnetic\":r\"1p_(old)\"}\n",
    "\n",
    "\n",
    "Name_Order = [\"One_Penny\",\"One_Penny_non_magnetic\",\"Two_Penny\",\"Two_Penny_non_magnetic\",\"Five_Pence\",\"Five_Pence_non_magnetic\",\n",
    "             \"Ten_Pence\",\"Ten_Pence_non_magnetic\",\"Twenty_Pence\",\"Fifty_Pence\",\"One_Pound\",\"Two_Pound\"]\n",
    "\n",
    "#How to scale\n",
    "Scale_type = 'Global'\n",
    "\n",
    "#Which file (This is not currently used)\n",
    "Scale_File = 'Coin_DataSet.csv'\n",
    "\n",
    "\n",
    "#Alpha scale\n",
    "Alpha_scale = 0.84\n",
    "\n",
    "#Sigma scale\n",
    "Sigma_scale = 12.5\n",
    "\n",
    "# Path Name for where the class data is stored\n",
    "Class_dir = \"Classes_Ben\"\n",
    "\n",
    "# Create a dictionary of these settings\n",
    "Creator_Settings = {\"Name\":Name,\"Frequencies\":Frequencies,\"Classes\":Classes,\"extend_results\":extend_results,\"Num_Results\":Num_Results,#\n",
    "                    \"class_split\":class_split,\"class_names\":class_names,\"Num_Results_class\":Num_Results_class,\"class_num_results\":class_num_results,\\\n",
    "                    \"Label_Data\":Label_Data,\"Name_Objects\":Name_Objects,\"Object_Names_dictionary\":Object_Names_dictionary,\"Name_Order\":Name_Order,\\\n",
    "                    \"Scale_type\":Scale_type,\"Scale_File\":Scale_File,\"Alpha_scale\":Alpha_scale,\"Sigma_scale\":Sigma_scale, \"Class_dir\":Class_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf2c8608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder path to the dataset is: British-Coins-Updated-1p-2p/Coins-100-inv_Al_0.84_Sig_12.5\n",
      "Class type is a list\n",
      "Five_Pence_non_magnetic\n",
      "One_Pound\n",
      "Two_Penny\n",
      "Two_Penny_non_magnetic\n",
      "Two_Pound\n",
      "Five_Pence\n",
      "One_Penny_non_magnetic\n",
      "Ten_Pence_non_magnetic\n",
      "Twenty_Pence\n",
      "Ten_Pence\n",
      "Fifty_Pence\n",
      "One_Penny\n",
      "(1200, 28) 28\n"
     ]
    }
   ],
   "source": [
    "# Run the Creator script\n",
    "from Creator import *\n",
    "#DataSet_Name=Creator(Name,Frequencies,Classes,extend_results,Num_Results,class_split,class_names,\\\n",
    "#            Num_Results_class,class_num_results,Label_Data, Name_Objects,Object_Names_dictionary,Name_Order,Scale_type,Scale_File,\\\n",
    "#            Alpha_scale,Sigma_scale)\n",
    "DataSet_Name=Creator(Creator_Settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96be8df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "British-Coins-Updated-1p-2p/Coins-100-inv_Al_0.84_Sig_12.5\n"
     ]
    }
   ],
   "source": [
    "# This is the dataset name to be used with the classifier\n",
    "\n",
    "#DataSet_Name=\"British-Coins-Updated-1p-2p/Coins-100_Al_0.84_Sig_12.5\"\n",
    "#DataSet_Name=\"British-Coins-Updated-1p-2p/Coins-100_Al_0.84_Sig_12.5\"\n",
    "DataSet_Name=\"British-Coins-Updated-1p-2p/Coins-100-inv_Al_0.84_Sig_12.5\"\n",
    "print(DataSet_Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb993227",
   "metadata": {},
   "source": [
    "**The next part involves running the actual classifier. This is done using Trainer_PDL.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adca0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option to load external testing data from disk. Requires that external_file_loader.py be run first.\n",
    "Load_External_Data = False \n",
    "# Option to plot comparison figures between the input array of simulated data and the external test data.\n",
    "# Currently only supported for a single class test set.\n",
    "Plot_Comparison_Figures = True\n",
    "# Option to additionally save to disk: the model for each bootstrap iteration, the normalisation coefficients for each,\n",
    "# bootstrap iteration, and the input array for each model, Used for debugging.\n",
    "Full_Save = False\n",
    "\n",
    "# Option to use SVD to reduce the number of features\n",
    "Reduce_Features = False\n",
    "\n",
    "#Model to be used\n",
    "#Optional models 'LogisticRegression', 'SVM', 'DecisionTree', 'RandomForest', 'GradientBoost', 'MLP','MLP,(n1,n2,...,nn)'\n",
    "Models_to_run = ['LogisticRegression']#,'SVM','GradientBoost']\n",
    "\n",
    "#Features\n",
    "Features = ['AngleRtildeI']#['Pri1','Pri2','Pri3']#['AngleRtildeI']#\n",
    "# Features = ['Eig1', 'Eig2', 'Eig3']\n",
    "#(list) list of features to be used options:\n",
    "#'Eig1','Eig2','Eig3','Pri1','Pri2','Pri3','Dev2','Dev3','Com','AngleRtildeI'\n",
    "#Eigenvalues, Principal invarients, Deviatoric invarients, Comutator, Angle between Rtilde and I\n",
    "\n",
    "#How many times would you like to train the model\n",
    "Bootstrap_Repetitions = 1\n",
    "#(int) how many times to train the model to obtain an average accuracy\n",
    "\n",
    "# use default levels of SNR\n",
    "SNR_array=[]\n",
    "\n",
    "# Make plot of first two reduced invairants\n",
    "Plot_Principal_Componenets = False\n",
    "\n",
    "Trainer_Settings = {\"DataSet_Name\": DataSet_Name, \"Load_External_Data\":Load_External_Data, \"Plot_Comparison_Figures\":Plot_Comparison_Figures,\\\n",
    "                   \"Full_Save\": Full_Save, \"Reduce_Features\":Reduce_Features, \"Models_to_run\": Models_to_run, \"Features\":Features, #\n",
    "                    \"Bootstrap_Repetitions\": Bootstrap_Repetitions, \"SNR_array\": SNR_array, \"Plot_Principal_Componenets\": Plot_Principal_Componenets }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d510a2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 22:05:45.128449: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-17 22:05:45.130980: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-17 22:05:45.167339: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-17 22:05:45.168101: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-17 22:05:45.880788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level =  5\n",
      "(1200, 504)\n",
      "(1200, 30) (1200, 28)\n",
      "Data [[-7.25113214e-11 -1.63141836e-10 -2.90010239e-10 ...  4.14401578e-08\n",
      "   7.94693910e-08  1.35649943e-07]\n",
      " [-7.25113214e-11 -1.63141836e-10 -2.90010239e-10 ...  8.67265710e-09\n",
      "   9.11882971e-08  2.59371809e-07]\n",
      " [-7.25113214e-11 -1.63141836e-10 -2.90010239e-10 ...  7.55328814e-08\n",
      "   7.83101046e-08  1.62713134e-07]\n",
      " ...\n",
      " [ 5.78392560e-07  5.68245963e-07  5.56157557e-07 ...  5.67618093e-04\n",
      "   6.19750582e-04  6.36677236e-04]\n",
      " [ 5.78392560e-07  5.68245963e-07  5.56157557e-07 ...  4.49389759e-04\n",
      "   5.62480911e-04  6.19130092e-04]\n",
      " [ 5.78392560e-07  5.68245963e-07  5.56157557e-07 ...  4.50829761e-04\n",
      "   5.63220829e-04  6.19439979e-04]]\n",
      "to here\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/Coding/MPT_Classifier_Testing/MPT_Classifier/Functions/Plot_comparison_features.py:177: UserWarning: \n",
      "The palette list has fewer values (10) than needed (12) and will cycle, which may produce an uninterpretable plot.\n",
      "  total_lineplot = sns.lineplot(data=internal_dataframe, x='omega',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level =  10\n",
      "(1200, 504)\n",
      "(1200, 30) (1200, 28)\n",
      "Data [[-7.25113214e-11 -1.63141836e-10 -2.90010239e-10 ...  4.14401578e-08\n",
      "   7.94693910e-08  1.35649943e-07]\n",
      " [-7.25113214e-11 -1.63141836e-10 -2.90010239e-10 ...  8.67265710e-09\n",
      "   9.11882971e-08  2.59371809e-07]\n",
      " [-7.25113214e-11 -1.63141836e-10 -2.90010239e-10 ...  7.55328814e-08\n",
      "   7.83101046e-08  1.62713134e-07]\n",
      " ...\n",
      " [ 5.78392560e-07  5.68245963e-07  5.56157557e-07 ...  5.67618093e-04\n",
      "   6.19750582e-04  6.36677236e-04]\n",
      " [ 5.78392560e-07  5.68245963e-07  5.56157557e-07 ...  4.49389759e-04\n",
      "   5.62480911e-04  6.19130092e-04]\n",
      " [ 5.78392560e-07  5.68245963e-07  5.56157557e-07 ...  4.50829761e-04\n",
      "   5.63220829e-04  6.19439979e-04]]\n",
      "to here\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/Coding/MPT_Classifier_Testing/MPT_Classifier/Functions/Plot_comparison_features.py:177: UserWarning: \n",
      "The palette list has fewer values (10) than needed (12) and will cycle, which may produce an uninterpretable plot.\n",
      "  total_lineplot = sns.lineplot(data=internal_dataframe, x='omega',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level =  15\n",
      "(1200, 504)\n",
      "(1200, 30) (1200, 28)\n",
      "Data [[-7.25113214e-11 -1.63141836e-10 -2.90010239e-10 ...  4.14401578e-08\n",
      "   7.94693910e-08  1.35649943e-07]\n",
      " [-7.25113214e-11 -1.63141836e-10 -2.90010239e-10 ...  8.67265710e-09\n",
      "   9.11882971e-08  2.59371809e-07]\n",
      " [-7.25113214e-11 -1.63141836e-10 -2.90010239e-10 ...  7.55328814e-08\n",
      "   7.83101046e-08  1.62713134e-07]\n",
      " ...\n",
      " [ 5.78392560e-07  5.68245963e-07  5.56157557e-07 ...  5.67618093e-04\n",
      "   6.19750582e-04  6.36677236e-04]\n",
      " [ 5.78392560e-07  5.68245963e-07  5.56157557e-07 ...  4.49389759e-04\n",
      "   5.62480911e-04  6.19130092e-04]\n",
      " [ 5.78392560e-07  5.68245963e-07  5.56157557e-07 ...  4.50829761e-04\n",
      "   5.63220829e-04  6.19439979e-04]]\n",
      "to here\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/Coding/MPT_Classifier_Testing/MPT_Classifier/Functions/Plot_comparison_features.py:177: UserWarning: \n",
      "The palette list has fewer values (10) than needed (12) and will cycle, which may produce an uninterpretable plot.\n",
      "  total_lineplot = sns.lineplot(data=internal_dataframe, x='omega',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level =  20\n",
      "(1200, 504)\n",
      "(1200, 30) (1200, 28)\n",
      "Data [[-7.25113214e-11 -1.63141836e-10 -2.90010239e-10 ...  4.14401578e-08\n",
      "   7.94693910e-08  1.35649943e-07]\n",
      " [-7.25113214e-11 -1.63141836e-10 -2.90010239e-10 ...  8.67265710e-09\n",
      "   9.11882971e-08  2.59371809e-07]\n",
      " [-7.25113214e-11 -1.63141836e-10 -2.90010239e-10 ...  7.55328814e-08\n",
      "   7.83101046e-08  1.62713134e-07]\n",
      " ...\n",
      " [ 5.78392560e-07  5.68245963e-07  5.56157557e-07 ...  5.67618093e-04\n",
      "   6.19750582e-04  6.36677236e-04]\n",
      " [ 5.78392560e-07  5.68245963e-07  5.56157557e-07 ...  4.49389759e-04\n",
      "   5.62480911e-04  6.19130092e-04]\n",
      " [ 5.78392560e-07  5.68245963e-07  5.56157557e-07 ...  4.50829761e-04\n",
      "   5.63220829e-04  6.19439979e-04]]\n",
      "to here\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/Coding/MPT_Classifier_Testing/MPT_Classifier/Functions/Plot_comparison_features.py:177: UserWarning: \n",
      "The palette list has fewer values (10) than needed (12) and will cycle, which may produce an uninterpretable plot.\n",
      "  total_lineplot = sns.lineplot(data=internal_dataframe, x='omega',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level =  40\n",
      "(1200, 504)\n",
      "(1200, 30) (1200, 28)\n",
      "Data [[-7.25113214e-11 -1.63141836e-10 -2.90010239e-10 ...  4.14401578e-08\n",
      "   7.94693910e-08  1.35649943e-07]\n",
      " [-7.25113214e-11 -1.63141836e-10 -2.90010239e-10 ...  8.67265710e-09\n",
      "   9.11882971e-08  2.59371809e-07]\n",
      " [-7.25113214e-11 -1.63141836e-10 -2.90010239e-10 ...  7.55328814e-08\n",
      "   7.83101046e-08  1.62713134e-07]\n",
      " ...\n",
      " [ 5.78392560e-07  5.68245963e-07  5.56157557e-07 ...  5.67618093e-04\n",
      "   6.19750582e-04  6.36677236e-04]\n",
      " [ 5.78392560e-07  5.68245963e-07  5.56157557e-07 ...  4.49389759e-04\n",
      "   5.62480911e-04  6.19130092e-04]\n",
      " [ 5.78392560e-07  5.68245963e-07  5.56157557e-07 ...  4.50829761e-04\n",
      "   5.63220829e-04  6.19439979e-04]]\n",
      "to here\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/Coding/MPT_Classifier_Testing/MPT_Classifier/Functions/Plot_comparison_features.py:177: UserWarning: \n",
      "The palette list has fewer values (10) than needed (12) and will cycle, which may produce an uninterpretable plot.\n",
      "  total_lineplot = sns.lineplot(data=internal_dataframe, x='omega',\n"
     ]
    }
   ],
   "source": [
    "from Trainer_PDL import *\n",
    "\n",
    "#main(DataSet_Name,Load_External_Data,Plot_Comparison_Figures,Full_Save,Reduce_Features,Models_to_run,Features,Bootstrap_Repetitions)\n",
    "main(Trainer_Settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b5a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f4d7e-007a-470d-a072-3910c7c28cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
